---
layout: post
title: <font color=#DC143C>案例一：邮件的分类与识别</font>
subtitle: 一个粗糙的分类器应用
bigimg: /pics/20170212/01.jpg
tags: [<font color=#FFE4C4>不易识别的正常邮件, 易识别的正常邮件, 垃圾邮件</font>]
---

&emsp;&emsp;本文所使用的数据来自于`Spam Assassin`的[公开语料库](http://spamassassin.apache.org/publiccorpus/)，
读者可以点击链接进行免费下载。这些文件由两套数据构成，分别用作训练集和测试集使用。而在每套数据中，均包含不易识别的正常邮件`(hard ham)`，易识别的正常邮件`(easy ham)`以及垃圾邮件`(spam)`的语料。我们的目标是建立一个简单有效的分类器，识别正常邮件和垃圾邮件。

&emsp;&emsp;那么，我们根据什么样的特征来区分正常邮件和垃圾邮件呢？根据以往的经验，词频`(word count)`信息将作为最重要的依据。
在对训练集数据整理的过程中，我们会发现，某些单词在垃圾邮件中高频出现，而在正常的邮件当中很少出现甚至不出现。对于另一些单词，情况可能恰恰相反。
根据经典的贝叶斯统计理论，我们可以计算出在给定一封邮件内容的情况下，其属于正常邮件和垃圾邮件的概率分别为多少。
取两者中较大的概率，并将邮件归于相应的类别。这就是我们建立分类器的原理。

### 训练集数据的整理和分析

&emsp;&emsp;我们将所下载的语料保存在当前工作目录下名为`data`的文件夹里，并整理成下图的形式，以便之后对数据的提取。

![](/pics/20170212/02.png)

&emsp;&emsp;完成上述的工作后，我们释放`R`的内存空间，加载本例所需的程序包，并提取语料的存储路径。

```r
rm(list = ls())
gc()

library(tm)
library(ggplot2)
library(data.table)
library(magrittr)
library(purrr)

spam.path <- "data/spam"
easyham.path <- "data/easy_ham"
hardham.path <- "data/hard_ham"

spam2.path <- "data/spam_2"
easyham2.path <- "data/easy_ham_2"
hardham2.path <- "data/hard_ham_2"
```

&emsp;&emsp;由于我们只关注于邮件的正文部分，所以需要设置一个能够提取邮件正文内容的函数。通常情况下，
我们会发现邮件的正文总是开始于文件中的第一个空行后（但有时候并没如此）。根据这样的规律，我们得到`get.msg`函数。

```r
get.msg <- function(path)
          {
             con <- file(path, open = "rt", encoding = "latin1")
             text <- readLines(con)
             close(con)
             id <- which(text == "")
             len  <- length(text)
             # The message always begins after the first full line break
             if (length(id) != 0 & id[1] < len)
             {
               msg <- text[seq(id[1] + 1, len, 1)]
               return(paste(msg, collapse = "\n"))
             }
          }
 ```
