---
layout: post
title: <font color=#DC143C>案例二：一个智能收件箱系统</font>
subtitle: 一个简单的排序算法
bigimg: /pics/20170219/01.jpg
tags: [<font color=#FFE4C4>邮件优先级, log加权策略, 线程活跃度</font>]
---

&emsp;&emsp;在上一个案例中，我们建立了一个垃圾邮件的识别系统。在本例中，我们将继续对这些邮件进行处理。选取文件夹`easy_ham`中的易识别的正常邮件作为本例的数据来源，并将其中的一半数据作为训练集使用，另一半即为测试集。我们试图寻找一些能够影响邮件优先级的特征进行量化处理，从而可以将邮件根据这些值进行排序，这就是我们建立一个智能收件箱的排序系统的基本原理。

### 邮件优先级的特征和量化

&emsp;&emsp;那么，什么特征适合衡量一封邮件的优先级呢？我们参照了一些相关资料，大致确定出以下五项特征作为评判一份邮件优先级的量化标准。

1. **社交特征**。如果发件人与收件人之间的交互频繁，那么可以认为来自该发件人的邮件对于收件人来说是重要的。因此在量化邮件优先级时，社交特征这方面应分配一定的权重。
2. **线程的活跃度**。我们发现，一些邮件的主题`(Subject)`是以`"Re:"`开头的，说明这是某一线程的一部分，那么该线程是一个活跃的线程，我们可以认为收件人重视这样的主题内容，故在计算邮件优先级时，应给此类邮件赋予一个相对较高的权重。
3. **发件人在线程内的活跃度**。通常情况下，对于在活跃线程内的发件人，收件人更倾向于处理其发送的邮件。因此，此项也是考量的内容之一。
4. **活跃线程的词项**。有些词汇可能频繁地出现在活跃的线程当中，很可能是收件人对这方面感兴趣。因此，当一份邮件的主题中出现这样的高频词项，那么，我们认为这封邮件对于收件人来说是具有优先的地位的。
5. **所有邮件共有词项**。为了使排序的结果尽可能地准确和科学，我们需要利用更加全面的信息，所有邮件的共有词项是一个不错的选择。

&emsp;&emsp;但是，具体量化邮件优先级的方式是什么呢？对于每一封邮件，我们都能将以上的五个特征提取出来，其值均为相应的频数。然后利用*log*加权的策略，我们可以将其频数值进行对数变换，使得彼此之间的差距不至于过大，而又存在差别，这是一个非常有用的技巧。最后，我们将所有权重相乘，最终得到该邮件优先级的量化值。可以看出，这种想法其实非常简单，但不失为一种可行的方法。

### 实现一个智能排序系统

&emsp;&emsp;首先，做好数据准备的工作，包括加载相应的程序包以及设置邮件读取的路径。

```r
# Free the memory
rm(list = ls())
gc()

# Load libraries
library(tm)
library(ggplot2)
library(plyr)
library(magrittr)
library(data.table)
library(formattable)
library(dplyr)

# Set the global paths
easyham.path <- "data/easy_ham"
```

&emsp;&emsp;自定义一些函数，获取邮件的基本信息，如邮件的接收时间、发送地址、主题以及内容。分别将其命名为`get.date`、`get.from`、`get.subject`和`get.msg`。在此之前，我们还需要定义一个`msg.full`的函数读取邮件的全部语料信息，并且在最后，定义一个`parse.email`函数汇总上述谈到的四项内容以及邮件存储的路径。

&emsp;&emsp;<font color="#DC143C">以下提供相应的R语言代码，其中的细节不做解释，后同。</font>

```r
# Simply returns the full text of a given email message
msg.full <- function(path)
{
  con <- file(path, open = "rt", encoding = "latin1")
  msg <- readLines(con)
  close(con)
  return(msg)
}

# Retuns the email address of the sender for a given
# email message
get.from <- function(msg.vec)
{
  from <- msg.vec[grepl("From: ", msg.vec)]
  from <- strsplit(from, '[":<> ]')[[1]]
  from <- from[from  != "" & from != " "]
  return(from[grepl("@", from)][1])
}

# Similar to the function from Chapter 3, this returns
# only the message body for a given email.
get.msg <- function(msg.vec)
{
  msg <- msg.vec[seq(which(msg.vec == "")[1] + 1, length(msg.vec), 1)]
  return(paste(msg, collapse = "\n"))
}

# Retuns the subject string for a given email message
get.subject <- function(msg.vec)
{
  subj <- msg.vec[grepl("Subject: ", msg.vec)]
  if(length(subj) > 0)
  {
    return(strsplit(subj, "Subject: ")[[1]][2])
  }
  else
  {
    return("")
  }
}

# Retuns the date a given email message was received
get.date <- function(msg.vec)
{
  date <- msg.vec[grepl("^Date: ", msg.vec)][1]
  date <- strsplit(date, "\\+|\\-|: ")[[1]][2]
  date <- gsub("^\\s+|\\s+$", "", date)
  return(strtrim(date, 25))
}

# This function ties all of the above helper functions together.
# It returns a vector of data containing the feature set
# used to categorize data as priority or normal HAM
parse.email <- function(path)
{
  full.msg <- msg.full(path)
      date <- get.date(full.msg)
      from <- get.from(full.msg)
      subj <- get.subject(full.msg)
       msg <- get.msg(full.msg)
  return(c(date, from, subj, msg, path))
}
```

利用`parse.email`函数解析所有易识别的正常邮件，并将结果以数据框的形式进行保存。

```r
easyham.docs  <- easyham.path %>% dir() %>% .[. != "cmds"]
easyham.parse <- lapply(easyham.docs,
                        function(p) 
                        {
                        parse.email(file.path(easyham.path, p))
                        })

allparse.df        <- easyham.parse %>% 
                      do.call(rbind, .) %>% 
                      as.data.frame()
names(allparse.df) <- c("Date", "From.Email", "Subject", 
                        "Message", "Path")
```

&emsp;&emsp;我们希望将`allparse.df`中的每条记录按照邮件接收的时间进行排序。然而，其中的时间以两种不标准的格式储存，我们需要将它们化成标准格式后才能进行排序的工作。为此，我们定义一个统一化时间格式的函数，命名为`date.converter`。

```r
# Convert date strings to POSIX for comparison. Because the emails data
# contain slightly different date format pattners we have to account 
# for this by passining them as required partmeters of the function. 
date.converter <- function(dates, pattern1, pattern2)
{
  pattern1.convert       <- strptime(dates, pattern1)
  pattern2.convert       <- strptime(dates, pattern2)
  test                   <- is.na(pattern1.convert)
  pattern1.convert[test] <- pattern2.convert[test]
  return(pattern1.convert)
}

pattern1 <- "%a, %d %b %Y %H:%M:%S"
pattern2 <- "%d %b %Y %H:%M:%S"

Sys.setlocale("LC_TIME", "English")
allparse.df$Date <- allparse.df$Date %>% 
                    date.converter(pattern1, pattern2)
```

将该数据框按时间的升序排序后，取前一半的数据作为训练集使用，剩余的则用作测试集，同时，将所有字母小写化。
```r
# Convert emails and subjects to lower-case
allparse.df$Subject    %<>% tolower()
allparse.df$From.Email %<>% tolower()

# Order the messages chronologically
priority.df <- allparse.df[with(allparse.df, order(Date)), ]

# We will use the first half of the priority.df to train our priority 
# in-box algorithm. Later, we will use the second half to test.
priority.train <- priority.df[1:(round(nrow(priority.df) / 2)), ]
```

&emsp;&emsp;接下来，我们定义一系列函数计算五大特征的各自权重。这里对代码中出现的关键变量做简单的解释，细节部分还请读者自己琢磨。

+ *from.weight*: 社交特征
+ *senders.dt*: 发件人在线程内的活跃度
+ *thread.weights*: 线程的活跃度
+ *term.weights*: 活跃线程的词项
+ *msg.weights*: 所有邮件共有词项

```r
from.weight <- melt(with(priority.train, table(From.Email)), 
                    value.name="Freq")
from.weight %<>% arrange(Freq) %>%
                 as.data.table() %>% 
                 .[ , .(From.Email, Freq)] %>% 
                 mutate(Weight = log1p(Freq))

# This function is used to find threads within the data set.  The 
# obvious approach here is to use the 're:' cue from the subject
# line to identify message threads.
find.threads <- function(email.df)
{
  response.threads <- strsplit(email.df$Subject, "re: ")
  is.thread <- sapply(response.threads,
                      function(subj) ifelse(subj[1] == "", TRUE, FALSE))
  threads <- response.threads[is.thread]
  senders <- email.df$From.Email[is.thread]
  threads <- sapply(threads,
                    function(t) paste(t[t != ""], collapse = "re: "))
  return(cbind(senders,threads))
}

threads.matrix <- find.threads(priority.train)

# Using the matrix of threads generated by the find.threads function
# this function creates a data from of the sender's email, the 
# frequency of emails from that sender, and a log-weight for that 
# sender based on the freqeuncy of corresponence.
email.thread <- function(threads.matrix)
{
  senders        <- threads.matrix[, 1]
  senders.freq   <- table(senders)
  senders.matrix <- cbind(names(senders.freq),
                          senders.freq,
                          log1p(senders.freq))
  senders.df <- data.frame(senders.matrix, stringsAsFactors=FALSE)
  row.names(senders.df) <- 1:nrow(senders.df)
  names(senders.df)     <- c("From.EMail", "Freq", "Weight")
  senders.df$Freq       <- as.numeric(senders.df$Freq)
  senders.df$Weight     <- as.numeric(senders.df$Weight)
  return(senders.df)
}

senders.dt<- threads.matrix %>% email.thread() %>% as.data.table()

# As an additional weight, we can enhance our notion of a thread's 
# importance by measuring the time between responses for a given 
# email.  This function takes a given thread and the email.df data 
# frame to generate a weighting  based on this activity level.  
# This function returns a vector of thread activity, the time span 
# of a thread, and its log-weight.
thread.counts <- function(thread, email.df)
{
  # Need to check that we are not looking at the original message in a 
  # thread, so we check the subjects against the 're:' cue.
  thread.times <- email.df$Date[which(email.df$Subject == thread |
                              email.df$Subject == paste("re:", thread))]
  freq      <- length(thread.times)
  min.time  <- min(thread.times)
  max.time  <- max(thread.times)
  time.span <- as.numeric(difftime(max.time, min.time, units = "secs"))
  if(freq < 2)
  {
    return(c(NA, NA, NA))
  }
  else
  {
    trans.weight     <- freq / time.span
    log.trans.weight <- 10 + log(trans.weight, base = 10)
    return(c(freq, time.span, log.trans.weight))
  }
}

# This function uses the threads.counts function to generate a weights
# for all email threads.
get.threads <- function(threads.matrix, email.df)
{
  threads       <- unique(threads.matrix[, 2])
  thread.counts <- lapply(threads,
                          function(t) thread.counts(t, email.df))
  thread.matrix <- do.call(rbind, thread.counts)
  return(cbind(threads, thread.matrix))
}

# Now, we put all of these function to work to generate a training set
# based on our thread features.
thread.weights <- get.threads(threads.matrix, priority.train)
thread.weights <- data.frame(thread.weights, stringsAsFactors = FALSE)
names(thread.weights)   <- c("Thread", "Freq", "Response", "Weight")
thread.weights$Freq     <- as.numeric(thread.weights$Freq)
thread.weights$Response <- as.numeric(thread.weights$Response)
thread.weights$Weight   <- as.numeric(thread.weights$Weight)
thread.weights %<>% data.table() %>% 
                    subset(is.na(Freq) == F)


# Similar to what we did in Chapter 3, we create a simple function to 
# return a vector of word counts.  This time, however, we keep the TDM 
# as a free parameter of the function.
term.counts <- function(term.vec, control)
{
  vec.corpus <- Corpus(VectorSource(term.vec))
  vec.tdm    <- TermDocumentMatrix(vec.corpus, control = control)
  return(rowSums(as.matrix(vec.tdm)))
}

thread.terms <- term.counts(thread.weights$Thread,
                            control = list(stopwords = TRUE))
thread.terms <- names(thread.terms)

term.weights <- sapply(thread.terms,
                       function(t)
                       {
                        t %>% 
                        grepl(thread.weights$Thread, fixed = T) %>% 
                        thread.weights[., Weight] %>% 
                        mean
                       })
term.weights <- data.table(Term = names(term.weights),
                         Weight = term.weights,
               stringsAsFactors = FALSE)

# Finally, create weighting based on frequency of terms in email. 
# Will be similar to SPAM detection, but in this case weighting
# high words that are particularly HAMMMY.

msg.terms <- term.counts(priority.train$Message,
                         control = list(stopwords = TRUE,
                                        removePunctuation = TRUE,
                                        removeNumbers = TRUE))
msg.weights <- data.table(Term = names(msg.terms),
                        Weight = log(msg.terms, base = 10),
              stringsAsFactors = FALSE) %>% 
              subset(Weight > 0)
```

&emsp;&emsp;最后，定义函数`get.weights`获取权重以及函数`rank.message`计算邮件的优先级。将邮件进行优先级的排序并展示一些结果。

```r
# This function uses our pre-calculated weight data frames to look up
# the appropriate weightt for a given search.term.  We use the 'term'
# parameter to dertermine if we are looking up a word in the weight.df
# for it message body weighting, or for its subject line weighting.
get.weights <- function(search.term, weight.dt, term = TRUE)
{
  if(length(search.term) > 0)
  {
    if(term)
    {
      term.match <- match(names(search.term), weight.dt$Term)
    }
    else
    {
      term.match <- match(search.term, weight.dt$Thread)
    }
    match.weights <- weight.dt$Weight[!is.na(term.match)]
    if(length(match.weights) < 1)
    {
      return(1)
    }
    else
    {
      return(mean(match.weights))
    }
  }
  else
  {
    return(1)
  }
}

# Our final step is to write a function that will assign a weight to 
# each message based on all of our, we create a function that will 
# assign a weight to each message based on the mean weighting across 
# our entire feature set.
rank.message <- function(path)
{
  msg <- parse.email(path)
  # Weighting based on message author
  
  # First is just on the total frequency
  from <- ifelse(any(from.weight$From.Email == msg[2]),
                 from.weight$Weight[from.weight$From.Email == msg[2]],
                 1)
  
  # Second is based on senders in threads, and threads themselves
  thread.from <- ifelse(any(senders.dt$From.Email == msg[2]),
                        senders.dt$Weight[senders.df$From.EMail == msg[2]],
                        1)
  
  subj <- strsplit(tolower(msg[3]), "re: ")
  is.thread <- ifelse(subj[[1]][1] == "", TRUE, FALSE)
  if(is.thread)
  {
    activity <- get.weights(subj[[1]][2], thread.weights, term = FALSE)
  }
  else
  {
    activity <- 1
  }
  # Next, weight based on terms    
  
  # Weight based on terms in threads
  thread.terms <- term.counts(msg[3], control = list(stopwords = TRUE))
  thread.terms.weights <- get.weights(thread.terms, term.weights)
  
  # Weight based terms in all messages
  msg.terms <- term.counts(msg[4],
                           control = list(stopwords = TRUE,
                                          removePunctuation = TRUE,
                                          removeNumbers = TRUE))
  msg.weights <- get.weights(msg.terms, msg.weights)
  
  # Calculate rank by interacting all weights
  rank <- prod(from,
               thread.from,
               activity, 
               thread.terms.weights,
               msg.weights)
  
  return(c(msg[1], msg[2], msg[3], rank))
}

# Find splits again
train.paths <- priority.df$Path[1:(round(nrow(priority.df) / 2))] %>% 
               as.vector()
test.paths <- priority.df$Path[((round(nrow(priority.df) / 2)) + 1):nrow(priority.df)] %>% as.vector()

# Now, create a full-featured training set.
train.ranks <- train.paths %>% 
               lapply(rank.message) %>% 
               suppressWarnings()
train.ranks.matrix <- do.call(rbind, train.ranks)
train.ranks.matrix <- cbind(train.paths, train.ranks.matrix, "Training")
train.ranks.dt <- data.table(train.ranks.matrix, stringsAsFactors = FALSE)
names(train.ranks.dt) <- c("Message", "Date", "From", "Subj", "Rank", "Type")
train.ranks.dt[ , Rank := as.numeric(Rank)]

# Set the priority threshold to the median of all ranks weights
priority.threshold <- median(train.ranks.dt$Rank)

# Classify as priority, or not
train.ranks.dt[ , Priority := ifelse(Rank >= priority.threshold, 1, 0)]

# Now, test our ranker by performing the exact same procedure on the test data
test.ranks <- suppressWarnings(lapply(test.paths,rank.message))
test.ranks.matrix <- do.call(rbind, test.ranks)
test.ranks.matrix <- cbind(test.paths, test.ranks.matrix, "Testing")
test.ranks.dt <- data.table(test.ranks.matrix, stringsAsFactors = FALSE)
names(test.ranks.dt) <- c("Message","Date","From","Subj","Rank","Type")
test.ranks.dt[ , Rank := as.numeric(Rank)]
test.ranks.dt[ , Priority :=  ifelse(Rank >= priority.threshold, 1, 0)]

# Finally, we combine the data sets.
final.df      <- rbind(train.ranks.dt, test.ranks.dt) %>% as.data.frame()
final.df$Date <- date.converter(final.df$Date, pattern1, pattern2) %>% 
                 as.POSIXct()

(final.dt <- final.df %>% data.table() %>% setorder(-Date))

# Save final data set and plot results.
ggplot(subset(final.dt, Type == "Training"), aes(x = Rank)) +
       stat_density(aes(fill = Type, alpha = 0.65)) +
       stat_density(data = subset(final.dt, Type == "Testing"),
                    aes(fill = Type, alpha = 0.65)) +
       geom_vline(xintercept = priority.threshold, linetype = 2) +
       scale_alpha(guide = "none") +
       scale_fill_manual(values = c("Training" = "darkred", 
                                     "Testing" = "darkblue")) +
       theme_bw()

set.seed(1234)
table1 <- final.dt %>% subset(Priority == 1) %>% sample_n(5)
table2 <- final.dt %>% subset(Priority == 0) %>% sample_n(5)
table3 <- rbind(table1, table2)
table3 %<>% setorder(Date) %>% .[ , .(Date, From, Subj, Rank, Priority)]

list(Rank = color_bar("lightblue"),
     Subj = formatter("span", 
                      style = x ~ ifelse(x == "Re: ALSA (almost) made easy", 
                                         style(color = "brown", 
                                         font.weight = "bold"),
                                         NA)),
     From = formatter("span",
                      style = x ~ ifelse(x == "ville.skytta@iki.fi", 
                                         style(color = "orange", 
                                         font.weight = "bold"),
                                         ifelse(x == "rssfeeds@spamassassin.taint.org",
                                                style(color = "purple", 
                                                font.weight = "bold"),
                                                NA))),
     Priority = formatter("span", style = x ~ style(color = ifelse(x, 
                                                                   "green", 
                                                                   "red")),
                          x ~ icontext(ifelse(x, "ok", "remove"), 
                                       ifelse(x, "Yes", "No")))) %>%
  formattable(table3, .)
```
